 The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. So today we're going to close this chapter on the short chapter on Bayesian inference. Again, this was just an overview of what you can do in Bayesian inference. And last time, we started defining what's called Jeffries priors. So when you do Bayesian inference, you have to introduce a prior on your parameter. And we said that usually it's something that encodes your domain knowledge about where the parameter could be. But there's also some principle way to do it if you want to do Bayesian inference without really having to think about it. And for example, one of the natural priors were those non-informative priors. If you're on a compact set, it's a uniform prior over this set. If you're on an infinite set, you can still think of taking the all ones prior. And that's called a prior that's always equal to 1. And that's an improper prior if you're an infinite set or proportional to 1. And so another prior that you can think of in the case where you have a Fisher information which is well-defined is something called Jeffries prior. And this prior is a prior which is proportional to square root of the determinant of the Fisher information matrix. And if you're in one dimension, it's basically proportional to square root of the Fisher information coefficient, which we know, for example, is the asymptotic variance of the maximum likelihood estimator. And it turns out that it's basically so square root of this thing is basically 1 over the standard deviation of the maximum likelihood estimator. And so you can compute this. So you can compute for the maximum likelihood estimator. We know that the variance is going to be p1 minus p in the Bernoulli statistical experiment. So you get this 1 over square root of this thing. And for example, in the Gaussian setting, you actually have the Fisher information given in the multivariate one is actually going to be something like the identity matrix. So this is proportional to 1. It's the improper prior that you get in this case, meaning that for the Gaussian setting, no place where you center your Gaussian is actually better than any other. All right, so we basically left on this slide where we saw that Jeffries priors satisfy a reparameterization. They're invariant by transformation of your parameter, which is a desirable property. And in a way, it says that, well, if I have my prior on theta, and then I suddenly decide that theta is not the parameter I want to use to parameterize my problem, actually what I want is phi of theta. Think, for example, as theta being the mean of a Gaussian and phi of theta as being this mean to the cube. This is a one-to-one map phi. So for example, if I want to go from theta to theta cube, and now I decide that this is the actual parameter that I want, well, then it means that on this parameter, my original prior is going to induce another prior. And here it says, well, this prior is actually also Jeffries prior. So it's essentially telling you that for this new parameterization, if you take Jeffries prior, then you actually go back to having exactly something that's of the form of the curve of determinant of the Fisher information, but this time with respect to your new parameterization. And so why is this true? Well, it's just this change of variable theorem. So it's essentially telling you that if you call, let's call, let's call pi tilde of eta prior over eta, and you have pi of theta as the prior over theta, then just by, since eta is of the form phi of theta, just by change of variable, so that's essentially a probability result. It says that pi tilde of eta is equal to pi of theta times d theta over d eta. Sorry, is that the one? Actually, I'm going to have to write it because I always forget this. So if I take a function, so what I want is to check. OK. OK, so I want the function of eta that I can put here. And what I know is that this is h of phi of theta. So sorry, eta is phi of theta, right? Yeah. So what I'm going to do is I'm going to do the change of variable theta is phi inverse of eta. So eta is phi of theta, which means that d eta is equal to d, well, to phi prime of theta d theta. So when I'm going to write this, I'm going to get integral of h. Actually, let me write this as, I'm more comfortable writing this as e with respect to eta of h of eta. So that's just eta according to being drawn from the prior. And I want to write this as the integral of h of eta times some function, right? So this is the integral of h of phi of theta pi of theta d theta. Now, I'm going to do my change of variable. So this is going to be the integral of h of eta. And then pi of phi of theta is phi inverse of eta. And then d theta is phi prime of theta d theta. And so what is pi of phi theta? So this thing is proportional. So we're in, say, dimension 1. So it's proportional of square root of the Fisher information. And the Fisher information we know is the expectation of the square of the derivative of the log likelihood, right? So this is square root of the expectation of d over d theta of log of, well, now I need the density. Well, let's just call it l of theta. And I want this to be taken at phi inverse of eta squared. And then what I pick up is the, so I'm going to put everything under the square. So I get phi prime of theta squared d theta. So now I have the expectation of a square. This does not depend. So this is l of theta. This is the expectation of l of theta and x, right? That's for some variable. And the expectation here is with respect to x. That's just the definition of the Fisher information. So now I'm going to squeeze this guy into the expectation. It does not depend on x. It just acts as a constant. And so what I have now is that this is actually proportional to the integral of h eta times the square root of the expectation with respect to x of what? Well, here I have d over d theta of log of theta. And here, this guy is really d eta over d theta, right? So now what I'm really left by, so I get d over d theta times d theta over d eta. So that's just d over d eta of log of eta x. And then this guy is now becoming d eta, right? OK, so this was a mess. This is a complete mess because I actually want to use phi. I should not actually introduce phi at all. I should just talk about d eta over d theta type of things. And then that would actually make my life so much easier. OK, I'm not going to spend more time on this. This is really just the idea, right? You have square root of a square in there. And then when you do your change of variable, you just pick up a square. You just pick up something here. And so you just move this thing in there. You get a square. It goes inside the square. And so your derivative of the log-likelihood with respect to theta becomes a derivative of the log-likelihood with respect to eta. And that's the only thing that's happening here. I'm just being super sloppy for some reason. And then, of course, now what you're left with is that this is really just proportional. Well, this is actually equal. Everything is proportional, but this is equal to the Fisher information tilde with respect to eta now. You're doing this with respect to eta. And so that's your new prior with respect to eta. So one thing that you want to do once you have, so remember, when you actually compute your posterior, rather than having, so you start with a prior, and you have some observations, let's say x1 to xn, when you do Bayesian inference, rather than spitting out just some theta hat, which is an estimator for theta, you actually spit out an entire posterior distribution, pi of theta given x1, xn. So there's an entire distribution on the candidate's theta. And you can actually use this to perform inference rather than just having one number. And so you could actually build confidence regions from this thing. And so a Bayesian confidence interval, so if your set of parameters is included in the real line, then you can actually, it's not even guaranteed to be an interval. So let me call it a confidence region. So a Bayesian confidence region. So it's just a random subspace. So let's call it R, is included in theta. And when you had the deterministic one, we had a definition which was with respect to the randomness of the data. That's how you actually had a random subset. You had a random confidence interval. Here, it's actually conditioned on the data, but with respect to the randomness that you actually get from your posterior distribution. So such that the probability that your theta belongs to this confidence region, given x1, xn, is say at least 1 minus alpha. Let's just take it equal to 1 minus alpha. So that's a confidence region at level 1 minus alpha. So that's one way. So why would you actually, when I actually implement Bayesian inference, I'm actually spinning out that entire distribution. I need to summarize this thing to communicate it. I cannot just say this is this entire function. I want to know where are the regions of high probability, where my parameter is supposed to be. And so here, when I have this thing, what I actually want to have is something that says, well, I want to summarize this thing into some subset of the real line in which I'm sure that the area under the curve here of my posterior is actually 1 minus alpha. And there's many ways to do this. Right So one way to do this is to look at level sets. And so rather than actually, so let's say my posterior looks like this. I know, for example, if I have a Gaussian distribution, I can actually take my posterior to be, my posterior is actually going to be Gaussian. And what I can do is to try to cut it here on the y-axis so that now the area under the curve when I cut here is actually 1 minus alpha. So I have some threshold tau. If tau goes to plus infinity, then I'm going to have that this area under the curve here is going to 1 minus alpha. Well, no. So the area under the curve when tau is going to plus infinity, think of when tau is just like right here. So this is actually going to 0. And so I start here. And then I start going down and down and down and down until I actually get something which is going down to 1 plus alpha. And if tau is going down to 0, then my area under the curve is going to, if tau is here, I'm cutting nowhere. And so I'm getting 1. Agreed? Think of when tau is very close to 0, I'm cutting very far here. And so I'm getting some area under the curve which is almost everything. And so it's going to 1 as tau going down to 0. Yeah? Does this only work for the binomial model? No, it does not. So this is a picture. This picture, so those two things work for all of them. But when you have a binomial model, this is actually when things start to become interesting. So when we built a frequentist confidence interval, it was always of the form x bar plus or minus something. But now if I start to have a posterior that looks like this, I'm going to start cutting off. I'm going to have two. I mean, my confidence region is going to be the union of those two things. And it really reflects the fact that there is this bimodal thing. It's going to say, well, with high probability, I'm actually going to be either here or here. Now, the meaning here of a Bayesian confidence region and a confidence interval are completely distinct notions. And it's actually, I'm going to work out an example with you so that we can actually see that sometimes, I mean, both of them actually can come up with some crazy paradoxes. So since we don't have that much time, I will actually talk to you about why in some instances it's actually a good idea to think of Bayesian confidence intervals rather than frequentist ones. So before I go into more details about what those Bayesian confidence intervals are, let's remind ourselves, what does it mean to have a frequentist confidence interval? So when I have a frequentist confidence interval, let's say something like x bar n minus 1.96 sigma over root n. And x bar n plus 1.96 sigma over root n. So that's the confidence interval that you get for the mean of some Gaussian with known variance to be equal to sigma squared. So what we know is that the meaning of this is the probability that theta belongs to this is equal to 95%. And this, more generally, you can think of being q alpha over 2. And what you're going to get is 1 minus alpha here. So what does it mean here? Well, it means it looks very much like what we have here, except that we're not conditioning on x1, xn. And we should not, because there was a question like that in the midterm. If I condition on x1, xn, this probability is either 0 or 1. Because once I condition, so here, this probability actually here is with respect to the randomness in x1, xn. So if I condition, so let's call this thing R-Frac for frequentist. Well, given x1, xn, and actually, I don't need to know x1, xn really. What I need to know is what xn bar is. Well, this thing now is what? It's 1 if theta is in R. And it's 0 if theta is not in R. Right? That's all there is. This is a deterministic confidence interval once I condition on x1, xn. So I have a number. The average is maybe 3. And so I get 3. Either theta is between 3 minus 0.5 or in 3 plus 0.5, or it's not. And so there's basically, I mean, I write it as probability, but it's really not a probabilistic statement. It's either it's true or not. Agreed? So what does it mean to have a frequentist confidence interval? It means that if I were, and here is where the word frequentist comes from. It says that if I repeat this experiment over and over, meaning that on Monday, I collect a sample of size n, and I build a confidence interval. And then on Tuesday, I collect another sample of size n, and I build a confidence interval. And on Wednesday, I do this again and again. What's going to happen is the following. I'm going to have my truth theta that lives here. And then on Monday, this is the confidence interval that I build. So this is the real line. The truth theta is here, and this is the confidence interval I build on Monday. So x bar was here, and this is my confidence interval. On Tuesday, I build this confidence interval maybe. x bar was closer to theta, a bit smaller. But then on Wednesday, I build this confidence interval. I'm not here. It's not in there, and that's this case. It happens that it's just not in there. And then on Thursday, I build another one. I almost miss it, but I'm in there, et cetera. Maybe here I miss again. And so what it means to have a confidence interval. So what does it mean to have a confidence interval at 95%? Yeah, so it means that if I repeat this, the frequency of times, hence the word frequentist, at which I'm actually going to overlap, that I'm actually going to contain theta, should be 95%. That's what frequentist means. So it's just a matter of trusting that. So on one given thing, one given realization of your data, it's not telling you anything. It's there or not. So it's not really something that's actually something that assesses the confidence of your decision, such as theta is in there or not. It's something that assesses the confidence you have in the method that you're using. If you were to repeat it over and again, it would be the same thing. It would be 95% of the time correct. So for example, we know that we could build a test. So it's pretty clear that you can actually build a test for whether theta is equal to theta 0 or not equal to theta 0 by just checking whether theta 0 is in a confidence interval or not. And what it means is that if you actually are doing those tests at 5%, then it means that 5% of the time, if you do this over and again 5% of the time, you're going to be wrong. I mentioned my wife does market research. And she does maybe, I don't know, 100,000 tests a year. And if they do all of them at 1%, then it means that 1% of the time, which is a lot of time, when you do 100,000 a year, it's 1,000 of them are actually wrong. She's actually hedging against the fact that 1% of them are going to be wrong. That's 1,000 of them that are going to be wrong. Just like if you do this 100,000 times at 95%, 5,000 of those guys are actually not going to be the correct ones. So it's kind of scary, but that's the way it is. So that's what the frequentist interpretation of this is. Now, as I mentioned, when we started this Bayesian chapter, I said Bayesian statistics sort of converge to, I mean, Bayesian decisions and Bayesian methods sort of converge to frequentist methods. When the sample size is large enough, they sort of lead to the same decisions. And in general, they need not be the same, but they tend to actually, when the sample size is large enough to have the same behavior. Think about, for example, the posterior that you have when you have in the Gaussian case. We said that in the Gaussian case, what you're going to see is that it's as if you had an extra observation, which was essentially given by your prior. And now, what's going to happen is that when there's just one observation among n plus 1, it's really going to be totally drawn, and you won't see it when the sample size grows large. So Bayesian methods are particularly useful when you have a small sample size. And when you have a small sample size, the effect of the prior is going to be bigger. But most importantly, you're not going to have to repeat this thing over and again. You're going to have a meaning. You're going to have to have something that has a meaning for this particular data set that you have. When I said that the probability that theta belongs to r, and here I'm going to specify the fact that it's a Bayesian confidence region like this one, this is actually conditionally on the data that you've collected. It says, given this data, given the points that you have, just put in some numbers if you want in there. It's actually telling you the probability that theta belongs to this Bayesian thing, to this Bayesian confidence region. Here, since I've conditioned on x1, xn, this probability is really just with respect to theta drawn from the prior. And so now it has a slightly different meaning. It's just telling you that it's really making a statement about where the regions of high probability of your posterior are. Now, why is that useful? Well, there's actually an interesting story that goes behind Bayesian methods. Anybody knows the story of the USS, I think it's Scorpion? Do you know the story? So that was an American vessel that disappeared. I think it was close to Bermuda or something. But you can tell the story of the Malaysian Airlines, except that I don't think it's such a successful story. But the idea was essentially we're trying to find where this thing happened. And of course, you don't have this is a one-time thing. You actually need something that works once. You need something that works for this particular vessel. And you don't care if you go to the Navy and you tell them, well, here's the method. And for 95 out of 100 vessels that you're going to lose, we're going to be able to find it. And they want this to work for this particular one. And so they were looking, and they were diving in different places. And suddenly, they brought in this guy. I forget his name. I mean, there's a whole story about this on Wikipedia. And he started collecting the data that they had from different dives and maybe from currents. And he started to put everything. And he said, OK, what is the posterior distribution of the location of the vessel given all the things that I've seen? And what have you seen? Well, you've seen that it's not here, it's not there, and it's not there. And you've also seen that the currents were going that way, and the wind were going that way. And you can actually put some model and try to understand this. Now, given this, for this particular data that you have, you can actually think of having a two-dimensional density that tells you where it's more likely than that the vessel is. And where are you going to be looking for? Well, if it's a multimodal distribution, you're just going to go to the highest mode first, because that's where it's the most likely to be. And maybe it's not there. So you're just going to update your posterior based on the fact that it's not there and do it again. And actually, after two dives, I think, you actually found the thing. And that's exactly where Bayesian statistics start to kick in, because you put a lot of knowledge into your model. But you also can actually factor in a bunch of information. The model, you had to build a model that was actually taking into account currents and wind. And what you can have as a guarantee is that when you talk about the probability that this vessel is in this location, given what you've observed in the past, it actually has some sense. Whereas if you were to use a frequentist approach, then there's no probability. Either it's underneath this position or it's not. So that's actually where it starts to make sense. And so you can actually build this. And there's actually a lot of methods that are based on, for search, that are based on Bayesian methods. I think, for example, the Higgs boson was based on a lot of Bayesian methods, because this is something you need to find once. I mean, there was a lot of prior that has to be built in. So now you build this confidence interval. And the nicest way to do it is to use level sets. But again, just like for Gaussians, even in the Gaussian case, I decided to go at x bar plus or minus something. But I could go at something that's completely asymmetric. So what's happening is that here, this method guarantees that you're going to have the narrowest possible confidence interval. That's essentially what it's telling you. Because every time I'm choosing a point starting from here, I'm actually putting as much area under the curve as I can. So those are called Bayesian confidence interval. And I promised you that we're going to work on some example that actually sort of gives a meaning to what I just told you with actual numbers. So this is something that's taken from Wasserman's book. And it's coming from a paper, from a stats paper, from Wolpert and I don't know who from the 80s. And essentially, this is how it works. So assume that you have n equals 2 observations. And you have y1. So those observations are y1. Sorry, let's call them x1, which is theta plus epsilon 1, and x2, which is theta plus epsilon 2, where epsilon 1 and epsilon 2 are iid. And the probability that epsilon i is equal to plus 1 is equal to the probability that epsilon i is equal to minus 1 is equal to 1 half. So it's just a uniform sign, plus minus 1. Now, let's think about, so you're trying to do some inference on theta. Maybe you actually want to find some inference on theta that's actually based on, and that's based only on the epsilon x1 and x2. So I'm going to actually build a confidence interval. But what I really want to build is a, but let's start thinking about how I would find an estimator for those two things. Well, what values am I going to be getting? So I'm going to get either theta plus 1 or theta minus 1. And actually, I can get basically four different observations. Sorry, four different pairs of observations. Plus plus theta minus 1. Agreed? Those are the four possible observations that I can get. Agreed? Either they're both equal to plus 1, they're both equal to minus 1, or one of the two is equal to plus 1, the other one to minus 1 for the epsilons. So those are the four observations I can get. So in particular, if they take the same value, I know it's either theta plus 1 or theta minus 1. And if they take a different value, I know one of them is theta plus 1, and one is actually theta minus 1. So in particular, if I take the average of those two guys when they take different values, I know I'm actually getting theta right. So let's build a confidence region. So I'm actually going to take a confidence region, which is just a singleton. And I'm going to say the following. Well, if x1 is equal to x2, I'm just going to take x1 minus 1. So I'm just saying, well, I'm never going to be able to resolve whether it's plus 1 or minus 1 that actually gives me the best one. So I'm just going to take a dive and say, well, it's just plus 1. And then if they're different, then here I can do much better. I'm going to actually just take the average. Now, what I claim is that this is a confidence region. And by default, when I don't mention it, this is a frequentist confidence region at level 75%. So let's just check that. To check that this is correct, I need to check that the probability under the realization of x1 and x2 that theta belongs is one of those two guys is actually equal to 0.75. Yes? AUDIENCE 2 It's just a frequentist confidence interval does not need to be an interval. Actually, in this case, it's going to be an interval. But that's just what it means. Yeah, region for Bayesian was just because the confidence intervals, when we're frequentists, we tend to make them intervals because we want. But when you're Bayesian and you're doing this level set thing, you cannot really guarantee unless it's unimodal it's going to be an interval. So region is just a way to not have to say interval unless it's not. OK, so I have this thing. So what I need to check is the probability that theta is in one of those two things. So what I need to find is the probability that theta is in x1 minus 1 and x1 is not equal to x2. And those are disjoint events. So it's plus the probability that theta is in x1 plus x2 over 2 and x1. Sorry, that's equal. That's different. OK, and OK, just before we actually finish the computation, why do I have 75%? 75% is 3 quarters. So it means that we have four cases. And essentially, I did not account for one case. And it's true. I did not account for this case. When the both of the epsilon i's are equal to minus 1. So this is essentially the one I'm not going to be able to account for. And so we'll see that in a second. So in this case, we know that everything goes great. So in this case, this is a, OK, well, let's just write. Let's start from the first line. So the first line is the probability that theta is equal to x1 minus 1 and those two are equal. So this is the probability that theta is equal to, well, this is theta plus epsilon 1 minus 1. And epsilon 1 is equal to epsilon 2, because I can remove the theta from here. And I can actually remove the theta from here so that this guy here is just epsilon 1 is equal to 1. So when I intersect with this guy, it's actually the same thing as epsilon 1 is equal to 1 as well. Epsilon 2 is equal to 1 as well. So this first thing is actually equal to the probability that epsilon 1 is equal to 1 and epsilon 2 is equal to 1, which is equal to what? Yeah, 1 quarter, right? So that's just the first case over there. They're independent. Now, I still need to do the second one. So this case is what? Well, when those things are equal, x1 plus x2 over 2 is what? Well, I get theta plus theta over 2. So that's just equal to the probability that epsilon 1 plus epsilon 2 over 2 is equal to 0. And epsilon 1 is different from epsilon 2. Agreed? I just removed the thetas from these equations because they're just on both sides every time. OK, and so that means what? That means that the second part, so this thing is actually equal to 1 quarter plus the probability that epsilon 1 and epsilon 2 over 2 is equal to 0. I can remove the 2. So this is just the probability that 1 is 1 and the other 1 is minus 1, right? So that's equal to the probability that epsilon 1 is equal to 1 and epsilon 2 is equal to minus 1 plus the probability that epsilon 1 is equal to minus 1 and epsilon 2 is equal to plus 1, because they're disjoint events. So I can break them into the sum of the two. And each of those guys is also one of the atomic part of it. It's one of the basic things. And so each of those guys has probability 1 quarter. And so here, we can really see that we accounted for everything except for the case when epsilon 1 was equal to minus 1 and epsilon 2 was equal to minus 1. So this is 1 quarter. This is 1 quarter. So the whole thing is equal to 3 quarters. So now what we have is that the probability that epsilon 1 is in the probability that theta belongs to this confidence region is equal to 3 quarters. And that's very nice. But the thing is, some people are sort of, I mean, it's not super nice to be able to say this, because in a way, I know that if I observe x1 and x2 that are different, I know for sure that I actually got the right theta, that this confidence interval is actually happening with probability 1. And the problem is that I do not know, I cannot make this precise with the notion of frequency confidence intervals. Because frequency confidence intervals have to account for the fact that in the future, it might not be the case that x1 and x2 are different. So Bayesian confidence regions, by definition, well, they're all gone. But they're conditioned on the data that I have. And so that's what I want. I want to be able to make a statement conditionally on the data that I have. So if I want to be able to make this statement, I'm going to have to put, if I want to build a Bayesian confidence region, I'm going to have to put a prior on theta. So without loss of generality, I mean, maybe with, but let's say, assume that pi is a prior on theta. And let's assume that pi of j is strictly positive for all integers j equals, say, 0. Well, actually, for all j in the integers, positive or negative. So that's a pretty weak assumption on my prior. I'm just saying, I'm just assuming that theta is some integer. And now let's build our Bayesian confidence region. Well, if I want to build a Bayesian confidence region, I need to understand what my posterior is going to be. And if I want to understand what my posterior is going to be, I actually need to build a likelihood. So we know that it's the product of the likelihood and of the prior divided by, so what is my likelihood? So my likelihood is the probability of x1, x2 given theta. That's what the likelihood should be. And now let's say that, actually, just to make things a little simpler, let us assume that x1 is equal to, I don't know, 5, and x2 is equal to 7. So this is exactly, I'm not going to take the case where they're actually equal to each other, because I know that in this case, x1 and x2 are different. I know I'm going to actually nail exactly what theta is by looking at the average of those guys. Here, it must be that theta is equal to 6. So what I want is to compute the likelihood at 5 and 7. What is this likelihood? Well, if theta is equal to 6, that's just the probability that I observe 5 and 7. So what is the probability I observe 5 and 7? 1? That's 1 quarter, right? It's the probability I have minus 1 for the first epsilon 1. So if theta is 6, this is the probability that epsilon 1 is equal to minus 1, and epsilon 2 is equal to plus 1, which is equal to 1 quarter. So this probability is 1 quarter. If theta is different from 6, what is this probability? So if theta is different from 6, since we know that we've only loaded the integers, so if theta has to be another integer, what is the probability that I see 5 and 7? 0. So that's my likelihood. And if I want to know what my posterior is, well, it's just pi of theta times p of 5, 6 given theta divided by the sum over all t's, say, in z. So now I just need to normalize this thing. So of pi of t, p of 5, 6 given t. Agreed? That's just the definition of the posterior. But when I sum these guys, there's only one that counts. Because for those things, we know that this is actually equal to 0 for every t except for when t is equal to 6. So this entire sum here is actually equal to pi of 6 times p of 5, 7 given that theta is equal to 6, which we know is equal to 1 quarter. And I did not tell you what pi of 6 was. But it's the same thing here. The posterior for any theta that's not 6 is actually going to be this guy is going to be equal to 0, so I really don't care what this guy is. So what it means is that my posterior becomes what? It becomes the posterior pi of theta given 5 and 7 is equal to, well, when theta is not equal to 6, this is actually 0. So regardless of what I do here, I get something which is 0. 0 And if theta is equal to 6, what I get is pi of 6 times p of 5, 7 given 6, which I've just computed here, which is 1 quarter, divided by pi of 6 times 1 quarter. So it's the ratio of two things that are identical, so I get 1. So now my posterior tells me that given that I observe 5 and 7, the theta has to be 6 with probability 1. So now I sort of say that this thing here, so this is not something that actually makes sense when I talk about frequentist confidence intervals. They don't really make sense to talk about confidence intervals given something. And so now given that I observe 5 and 7, I know that the probability of theta is equal to 1. And in this sense, the Bayesian confidence interval is actually more meaningful. So one thing I want to actually say about this Bayesian confidence interval is that it's, I mean, here it's equal to the value 1, right? So it really encompasses the thing that we want. But the fact that we actually computed it using the Bayesian posterior and the Bayesian rule did not really matter for this argument. All I just said was that it had a prior. But just what I want to illustrate is the fact that we can actually give meaning to the probability that theta is equal to 6 given that I see 5 and 7, whereas we cannot really in the other cases. And we don't have to be particularly precise in the prior on theta to be able to give this meaning. All right. So now as I said, I think the main power of Bayesian inference is that it spits out the posterior distribution and not just the single number like frequentists would give you. Then we can say decorate our theta hat or point estimate with maybe some confidence interval. Maybe we can do a bunch of tests. But at the end of the day, we just have essentially one number, right? And maybe we can sort of understand what the fluctuations of this number are in a frequentist setup. But the Bayesian framework is essentially giving you a natural method. And you can interpret it in terms of the probabilities that are associated to the prior. But you can actually also try to make some, right? So a Bayesian, if you give me any prior, you're going to actually build an estimator from this prior, from the posterior. And maybe it's going to have some frequentist properties. And that's what's really nice about Bayesians is that you can actually try to give some frequentist properties of Bayesian methods that are built using Bayesian methodology. But you cannot really go the other way around. If I give you a frequentist methodology, how are you going to say something about the fact that there's a prior going on, et cetera? And so this is actually one of the things. There's actually some research that's going on for this. They call it Bayesian posterior concentration. And so there's something called the Bernstein-Von Mises theorem, or a class of theorems. And those are essentially methods that tell you, well, if I actually run a Bayesian method, and I look at the posterior that I get, it's going to be something like this. But now I try to study this in a frequentist point of view. There's actually a true parameter theta somewhere, the true one. There's no prior for this guy. This is just one fixed number. Is it true that as my sample size is going to go to infinity, then this thing is going to concentrate around theta? And the rate of concentration of this thing, the size of this with the standard deviation of this thing, is something that should decay maybe like 1 over square root of n or something like this. And the rate of posterior concentration, when you characterize it, is called the Bernstein-Von Mises theorem. And so people are looking at this in some nonparametric cases. You can do it in pretty much everything we've been doing before. You can do it for nonparametric regression estimation or density estimation. You can do it for, of course, you can do it for sparse estimation if you want. So you can actually compute the posterior. And so you can think of it as being just a method somehow. Now, the estimator I'm talking about, so that's just the general Bayesian posterior concentration. But you can also try to understand what is the property of something that's extracted from this posterior. And one thing that we actually described was, for example, well, given this guy, maybe it's a good idea to think about what the mean of this thing is. So there's going to be some theta hat, which is just the integral of theta pi theta given x1, xn. So that's my posterior d theta. So that's the posterior mean. That's the expected value with respect to the posterior distribution. And I want to know, how does this thing behave? How close it is to a true theta if I actually I'm in a frequency set? So that's the posterior mean. But this is not the only thing I can actually spit out. This is definitely uniquely defined. If you give me a distribution, I can actually spit out its posterior mean. But I can also think of the posterior median. But now, if this is not continuous, you might have some uncertainty. Maybe the median is not uniquely defined. And so maybe that's not something you use as much. Maybe you can actually talk about the posterior mode. So for example, if your posterior density looks like this, then maybe you just want to summarize your posterior with this number. So clearly, in this case, it's not such a good idea because you completely forget about this mode. But maybe that's what you want to do. Maybe you want to focus on the most peaked mode. And this is actually called maximum a posterior. As I said, maybe you want a sample from this posterior distribution. And so in all these cases, these Bayesian estimators will depend on the prior distribution. And the hope is that as the sample size grows, you won't see that again. So to conclude, let's just do a couple of experiments. So if I look at, did we do this? Yeah, so for example, so let's focus on the posterior mean. And we know, so remember in experiment one, sorry, in example one, what we had was x1, xn that were iid, Bernoulli p. And the prior I put on p was a beta with parameter aa. And if I go back to what we computed, you can actually compute the posterior of this thing. And we know that it's actually going to be, sorry, that was uniform. So what we get is that the posterior, this thing is actually going to be a beta with parameter a plus the sum. So a plus the number of 1's and a plus the number of 0's. And the beta was just something that looked like the density was p to the a minus 1, 1 minus p. So if I want to understand the posterior mean, I need to be able to compute the expectation of a beta and then maybe plug in a for a plus this guy, a minus this guy. So actually, let me do this. So what is the expectation? So what I want is something that looks like the integral between 0 and 1 of p times a minus 1, sorry, p times p a minus 1, 1 minus p, b minus 1. Do we agree that this, and then there's a normalizing constant. Let's call it c. So this is what I need to compute. So that's c of a and b. Do we agree that this is the posterior mean with respect to a beta with parameters a and b? I just integrate p against the density. So what does this thing look like? Well, I can actually move this guy in here. And here I'm going to have a plus 1 minus 1. So the problem is that this thing is actually, the constant is going to play a big role, because this is essentially equal to c a plus 1 b divided by c a b, where c a plus 1 b is just the normalizing constant of a beta a plus 1 b. So I need to know the ratio of those two constants. And this is not something, I mean, this is just a calculus exercise. So in this case, what you get is, sorry, in this case, you get, well, OK. So we get essentially a divided by, I think it's a plus b. Yeah, it's a plus b. OK. So that's this quantity. OK? And when I plug in a to be this guy and b to be this guy, what I get is a plus sum of dxi. And then I get a plus this guy, a plus n minus this guy. So those two guys go away. And I'm left with 2a plus n, which does not work. So yeah, no, that actually works. And so now what I do, I can actually divide and get this thing over there. OK, so what you can see, the reason why this thing has been divided is that you can really see that as n goes to infinity, then this thing behaves like xn bar, which is our frequentist estimator. The effect of a is actually going away. The effect of the prior, which is completely captured by a, is going away as n goes to infinity. Is there any question? You guys have a question. What is it? You have a question? Yeah. On the board, is that divided by the larger sum? I was thinking that, yeah. Is it divided by what? That a raised plus b, and then you just expand the real. Oh, yeah, yeah. I said that this is equal to this. So that's for a becomes a plus sum of the xi's, and b becomes a plus n minus sum of the xi's. OK, so that's just for the posterior one. What is the number that's like the 2a? This guy? Yeah. 2a? Right, so I get a plus a plus n, and then those two guys cancel. OK, and that's what you have here. So for a is equal to 1 half, and I claim that this is Jeffreys prior, because remember, Jeffreys was what? Well, it was square root. It was proportional to the square root of p 1 minus p, which I can write as p to the 1 half, 1 minus p to the 1 half. So it's just the case a is equal to 1 half. So if I use Jeffreys prior, I just plug in a equals to 1 half, and this is what I get. So those things are going to have an impact, again, when n is moderately large. For large n, those things, whether you take Jeffreys prior or you take whatever a you prefer, it's going to have no impact whatsoever. But if n is of the order of 10, maybe, then you're going to start to see some impact depending on what a you want to pick. OK, and in the second example, well, here we actually computed the posterior to be this guy. Well, here I can just read off what the expectation is. I mean, I don't have to actually compute the expectation of a Gaussian. It's just xn bar. And so in this case, there's actually no. I mean, when I have a non-informative prior for a Gaussian, then I have basically xn bar. And so as you can see, actually, this is an interesting example. When I actually look at the posterior, it's not something that costs me a lot to communicate to you. There's one symbol here, one symbol here, and one symbol here. I tell you the posterior is a Gaussian with mean xn bar and variance 1 over n. When I actually turn that into a posterior mean, I'm dropping all this information. I'm just giving you the first parameter. So you can see there's actually much more information in the posterior than there is in the posterior mean. The posterior mean is just a point. It's not telling me how confident I am in this point. And this thing is actually very interesting. So you can talk about the posterior variance that's associated to it. You can talk about, as an output, you could give the posterior mean and the posterior variance. And those things are actually interesting. All right, so I think this is it. So as I said, in general, just like in this case, the choice of the prior is being, the impact of the prior is being washed away as the sample size goes to infinity. Just like here, there's no impact of the prior. It was a non-informative one. But if you actually had an informative one, CF homework, you would actually see an impact of the prior, which again would be washed away as your sample size increases. Here it goes away. You just get xn bar over 1. And actually, in this case, you see that the Bayesian estimator is asymptotically normal. This is different from the distribution of the posterior. This is just the posterior mean, which happens to be asymptotically normal. But the posterior may not have a, I mean, here the posterior is a beta. I mean, it's not normal. So there's different, those things are two different things. Your question? What was the prior and the improper prior? All one, that was the improper prior. OK. And so that's because you're saying that there's an impact of the prior. Yeah. Just a quick question. Well, I mean, yeah, so it's essentially telling you that, so we said that when you have a non-informative prior, essentially the maximum likelihood is the maximum a posterior. But in this case, there's so much symmetry that it just so happens that the maximum, and this thing is completely symmetric around its maximum. So it means that the expectation is equal to the maximum, to the arg max. Yeah. I read somewhere that one of the issues with Bayesian methods is that if you choose the wrong prior, it could mess up your results. Yeah, but hence, do not pick the wrong prior. I mean, of course, it would. I mean, it would mess up your results. Of course. I mean, you're putting extra information. But you could say the same thing by saying, well, the issue with frequentist methods is that if you mess up the choice of your likelihood, then it's going to mess up your output. So here, you just have two chances of messing it up. You have the, well, it's gone. So you have the product of the likelihood and the prior. And you have one more chance to, but it's true. If you assume that the model is right, then of course, finding the wrong prior could completely mess up things if your prior, for example, has no support on the true parameter. But if your prior has a positive weight on the true parameter as n goes to infinity, you know, I mean, OK, I cannot speak for all counter examples in the world. But I'm sure under minor technical conditions, you can guarantee that your posterior mean is going to converge to what you need it to converge to. Any other question? All right. So I think this sort of closes the more traditional mathematical, not mathematical, but traditional statistics part of this class. And from here on, we'll talk about more multivariate statistics, starting with principal component analysis. So that's more like when you have multiple data. We started, in a way, to talk about multivariate statistics when we talked about multivariate regression. But we'll move on to principal component analysis. I'll talk a bit about multiple testing. I haven't made my mind yet about what we'll talk really in December. But I want to make sure that you have a taste and a flavor of what is being interesting in statistics these days, especially as you go towards more machine learning type of questions, where really the focus is on prediction rather than the modeling itself. I will talk about logistic regression as well, for example, which is in general like linear models, which is just the generalization in the case that y does not take value in the whole real line, maybe 0, 1, for example, for regression. All right, thanks.